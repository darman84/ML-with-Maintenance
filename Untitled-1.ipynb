{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  grad_scaler = amp.GradScaler()  # Renamed from scaler to grad_scaler\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting training...\n",
      "Epoch [5/50], Loss: 0.0967, Best F1: 0.2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.0880, Best F1: 0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 0.0874, Best F1: 0.2405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 0.0874, Best F1: 0.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 0.0877, Best F1: 0.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Loss: 0.0864, Best F1: 0.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Loss: 0.0856, Best F1: 0.2470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Loss: 0.0852, Best F1: 0.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Loss: 0.0856, Best F1: 0.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.0853, Best F1: 0.2539\n",
      "\n",
      "Final Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\AppData\\Local\\Temp\\ipykernel_74672\\1525978017.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    119117\n",
      "           1       0.22      0.30      0.25       742\n",
      "\n",
      "    accuracy                           0.99    119859\n",
      "   macro avg       0.61      0.65      0.62    119859\n",
      "weighted avg       0.99      0.99      0.99    119859\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[118331    786]\n",
      " [   520    222]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.cuda.amp as amp\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class TorchOneClassSVM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TorchOneClassSVM, self).__init__()\n",
    "        self.rbf_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, chunk_size=128):\n",
    "        batch_predictions = []\n",
    "        \n",
    "        for i in range(0, x.size(0), chunk_size):\n",
    "            end_idx = min(i + chunk_size, x.size(0))\n",
    "            chunk = x[i:end_idx]\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = self.rbf_layer(chunk)\n",
    "            \n",
    "            batch_predictions.append(output)\n",
    "            \n",
    "        return torch.cat(batch_predictions, dim=0)\n",
    "\n",
    "# Set up GPU and memory optimization\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "grad_scaler = amp.GradScaler()  # Renamed from scaler to grad_scaler\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('water_main_data.csv')\n",
    "df['Length'] = df['Length'].astype(str).str.replace(' ft', '').astype(float)\n",
    "df = df[df['Material'] != 'UNKNOWN']\n",
    "\n",
    "# Encode Material column\n",
    "material_encoder = OneHotEncoder(sparse_output=False)\n",
    "material_encoded = material_encoder.fit_transform(df['Material'].values.reshape(-1, 1))\n",
    "material_columns = [f'Material_{i}' for i in range(material_encoded.shape[1])]\n",
    "df_encoded = pd.DataFrame(material_encoded, columns=material_columns)\n",
    "\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "df['Installed'] = pd.to_datetime(df['Installed'])\n",
    "df['Year_Installed'] = df['Installed'].dt.year\n",
    "df = df.drop(columns=['Material', 'Installed'])\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(columns=['ID', 'Leak Occurred'])\n",
    "y = df['Leak Occurred']\n",
    "\n",
    "# Preprocessing\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Fix the MinMaxScaler implementation\n",
    "min_max_scaler = MinMaxScaler()  # Renamed from scaler to min_max_scaler\n",
    "X_scaled = min_max_scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "y_tensor = torch.FloatTensor(y.values).to(device)\n",
    "\n",
    "# Create DataLoader with GPU optimization\n",
    "batch_size = 256\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Initialize model and move to GPU\n",
    "model = TorchOneClassSVM(input_dim=X_tensor.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Change to BCEWithLogitsLoss\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor([5.0]).to(device)\n",
    ")\n",
    "\n",
    "# Training loop with GPU optimization\n",
    "num_epochs = 50\n",
    "best_f1 = 0\n",
    "best_threshold = 0.5\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits.squeeze(), batch_y)\n",
    "        \n",
    "        grad_scaler.scale(loss).backward()  # Using grad_scaler instead of scaler\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = model(X_tensor)\n",
    "            val_predictions = torch.sigmoid(val_logits)\n",
    "            \n",
    "            for threshold in np.arange(0.3, 0.7, 0.05):\n",
    "                pred_binary = (val_predictions.squeeze().cpu().numpy() > threshold).astype(int)\n",
    "                f1 = f1_score(y, pred_binary)\n",
    "                \n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, Best F1: {best_f1:.4f}')\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nFinal Evaluation...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_logits = model(X_tensor)\n",
    "    final_predictions = torch.sigmoid(final_logits)\n",
    "    final_predictions = (final_predictions.squeeze().cpu().numpy() > best_threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, final_predictions))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y, final_predictions))\n",
    "\n",
    "# Save results\n",
    "df['Predicted_Leak'] = final_predictions\n",
    "df.to_csv('predicted_leaks_gpu.csv', index=False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
